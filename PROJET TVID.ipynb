{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5400174",
   "metadata": {},
   "source": [
    "# PROJET TVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f3766e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff08a7f",
   "metadata": {},
   "source": [
    "## A. Jouer un flux MPEG-2 élémentaire de test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ab24bf",
   "metadata": {},
   "source": [
    "### 1. Dans le dossier videos/elementary, avec vlc, visualisez les séquences MPEG-2 suivantes : \n",
    "### _vlc -V \\<renderer> bw_numbers.m2v / pendulum.m2v / Jaggies1.m2v_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59153500",
   "metadata": {},
   "source": [
    "Les commandes utilisees sont :\n",
    "- vlc -V x11 bw_numbers.m2v\n",
    "- vlc -V x11 pendulum.m2v\n",
    "- vlc -V x11 Jaggies1.m2v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a879069",
   "metadata": {},
   "source": [
    " <img src=\"./screenshots/1.png\" title=\"bw_numbers\">\n",
    " <img src=\"./screenshots/2.png\" title=\"pendulum\">\n",
    " <img src=\"./screenshots/3.png\" title=\"Jaggles1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e437c0",
   "metadata": {},
   "source": [
    "### 2. Avec mpeg2dec, convertissez en pile d’images votre séquence MPEG-2 choisie (cf. aide de mpeg2dec)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d891d942",
   "metadata": {},
   "source": [
    "Nous avons cree un dossier pgm_images a la racine du projet, et avons effectue cette commande :\n",
    "- _../tools/mpeg2dec/src/mpeg2dec -o pgm ../videos/elementary/bw_numbers.m2v_\n",
    "\n",
    "Pour convertir la sequence bw_numbers.m2v en pile d'images.\n",
    "\n",
    " <img src=\"./screenshots/pgm_0.png\" title=\"0\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5f5574",
   "metadata": {},
   "source": [
    "### 3. Observez les pgm générées. Comment sont-elles structurées? Quel est le format de l’image: résolution, profondeur, sampling mode?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcdf12c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format: PPM\n",
      "Resolution: (720, 720)\n",
      "Mode: L\n",
      "Color palette: None\n"
     ]
    }
   ],
   "source": [
    "img = Image.open('./pgm_images/0.pgm')\n",
    "\n",
    "print(f\"Format: {img.format}\")\n",
    "print(f\"Resolution: {img.size}\")\n",
    "print(f\"Mode: {img.mode}\")\n",
    "print(f\"Color palette: {img.palette}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee562dd",
   "metadata": {},
   "source": [
    "Nos images sont au format PGM encodes en binaire. Ce sont des images en niveaux de gris (sur 8-bit). Elles ont une resolution de 720x720.\n",
    "\n",
    " <img src=\"./screenshots/bw_numbers_infos.png\" title=\"bw_numbers_infos\">\n",
    " \n",
    "En regardant les informations de la video originale, nous pouvons voir que la resolution est de 720x480, que la profondeur est de 8-bit, et que le sampling mode est en 4:2:0 YUV.\n",
    "\n",
    "Les frames sont composes de 2 images consécutives entrelacées dans une même image (top first field).\n",
    "\n",
    "Les informations de la video ont ete generees par cette commande :\n",
    "- ffmpeg -i bw_numbers.m2v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363171a8",
   "metadata": {},
   "source": [
    "### 4. Modifiez mpeg2dec pour logger simplement les flags progressive_frame, top_field_first, repeat_first_field de chaque image décodée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9655f813",
   "metadata": {},
   "source": [
    "Pour logger simplement les flags progressive_frame (PROG), top_field_first (TFF) et repeat_first_field (RFF) pour chaque image decodee, il faut modifier le fichier :\n",
    "- mpeg2dec/src/mpeg2dec.c, ligne 55\n",
    "\n",
    "en mettant la variable __verbose__ a 1 :\n",
    "- static int verbose = 1;\n",
    "\n",
    "On obtient par exemple ces logs pour la video bw_numbers.m2v :\n",
    " <img src=\"./screenshots/bw_numbers_logs.png\" title=\"bw_numbers_logs\">\n",
    " \n",
    "Les images decodee ici sont toutes TFF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706a603d",
   "metadata": {},
   "source": [
    "### 5. Avec votre propre code et dans le langage de votre choix, implémentez un convertisseur d’images vers un format plus humainement lisible (ppm RGB est assez universel)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70424c36",
   "metadata": {},
   "source": [
    "Le langage choisi est Python.\n",
    "\n",
    "Nous savons que nos images sont en format YUV 4:2:0. \n",
    "\n",
    "Cela signifie que pour un carree de 4 pixels, les 4 contiennent une information de luminance, mais seulement un contient une information de chrominance u, et un autre contient une information de chrominance v :\n",
    "<img src=\"./screenshots/420.png\" title=\"420\">\n",
    "\n",
    "Nous avons remarque que 2/3 de nos image PGM etait consacre a donne l'information de luminance, un sixieme etait consacre a donne l'information de chrominance u, et un autre sixieme etait consacre a donne l'information de chrominance v. \n",
    "\n",
    "Nous avons alors isole les differentes parties de l'image en fonction du type d'information qu'elles conviaient.\n",
    "\n",
    "Nous avons ensuite elargi nos arrays de chrominances en dupliquant les valeurs en largeur et en hauteur pour matcher la shape de l'array de luminance, avant de les concatener en un seul array.\n",
    "\n",
    "Nous avons enfin normalise et converti nos valeurs YUV en RGB par une relation trouvee sur la page wikipedia sur le format YUV :\n",
    "<img src=\"./screenshots/normalization.png\" title=\"normalization\">\n",
    "<img src=\"./screenshots/conversion_formula.png\" title=\"conversion_formula\">\n",
    " \n",
    "La conversion de PGM YUV 4:2:0 en PPM RGB est alors naturel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1015f2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def YUV_to_RGB(y, u, v) :\n",
    "    r = y + 1.13983 * v\n",
    "    g = y - 0.39465 * u - 0.58060 * v\n",
    "    b = y + 2.03211 * u\n",
    "    \n",
    "    return r, g, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09fa9ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PGM_to_PPM(yuv_array, TFF=True) :\n",
    "    # loading pgm info\n",
    "\n",
    "    height, width = yuv_array.shape\n",
    "    \n",
    "    uv_width = width // 2\n",
    "    y_height = int(height * 2 / 3)\n",
    "    \n",
    "    # extraction\n",
    "    \n",
    "    y_array = yuv_array[0:y_height, 0:width]\n",
    "    u_array = yuv_array[y_height:height, 0:uv_width]\n",
    "    v_array = yuv_array[y_height:height, uv_width:width]\n",
    "    \n",
    "    # duplication (to match the size of y)\n",
    "    \n",
    "    u_array = np.repeat(np.repeat(u_array, 2, axis=1), 2, axis=0)\n",
    "    v_array = np.repeat(np.repeat(v_array, 2, axis=1), 2, axis=0)\n",
    "    \n",
    "    if TFF :\n",
    "        y_array = np.repeat(y_array, 2, axis=0)\n",
    "        u_array = np.repeat(u_array, 2, axis=0)\n",
    "        v_array = np.repeat(v_array, 2, axis=0)\n",
    "        \n",
    "        y_height *= 2\n",
    "    \n",
    "    # normalization\n",
    "\n",
    "    y_array = y_array / 255\n",
    "    \n",
    "    u_max = 0.436\n",
    "    u_min = -u_max\n",
    "    u_array = u_min + (u_array / 255) * 2 * u_max\n",
    "    \n",
    "    v_max = 0.615\n",
    "    v_min = -v_max\n",
    "    v_array = v_min + (v_array / 255) * 2 * v_max\n",
    "    \n",
    "    # stacking\n",
    "    \n",
    "    yuv_data = np.stack((y_array, u_array, v_array), axis=-1)\n",
    "    \n",
    "    # conversion to rgb data between [0, 1]\n",
    "    \n",
    "    rgb_data = []\n",
    "    \n",
    "    for i in range(y_height) :\n",
    "        rgb_data.append([])\n",
    "        \n",
    "        for j in range(width) :\n",
    "            y = yuv_data[i][j][0]\n",
    "            u = yuv_data[i][j][1]\n",
    "            v = yuv_data[i][j][2]\n",
    "            \n",
    "            r, g, b = YUV_to_RGB(y, u, v)\n",
    "            \n",
    "            rgb_data[i].append([r, g, b])\n",
    "            \n",
    "    rgb_data = np.array(rgb_data)\n",
    "    \n",
    "    rgb_data = np.clip(rgb_data, 0, 1)\n",
    "            \n",
    "    # conversion to uint-8 values between [0, 255]\n",
    "    \n",
    "    rgb_data = (rgb_data * 255).astype('uint8')\n",
    "    \n",
    "    return rgb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea27ca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_PGM_to_PPM(pgm_path, ppm_path=None, TFF=True) :\n",
    "    # loading pgm\n",
    "    \n",
    "    img = Image.open(pgm_path)\n",
    "    \n",
    "    yuv_array = np.array(img)\n",
    "    \n",
    "    # top first field order\n",
    "    \n",
    "    if TFF :\n",
    "        rgb_data_top = PGM_to_PPM(yuv_array[::2], TFF=True)\n",
    "        rgb_data_bottom = PGM_to_PPM(yuv_array[1::2], TFF=True)\n",
    "        \n",
    "        # saving as ppm\n",
    "        \n",
    "        if ppm_path :\n",
    "            new_img_1 = Image.fromarray(rgb_data_top)\n",
    "            new_img_2 = Image.fromarray(rgb_data_bottom)\n",
    "            \n",
    "            new_img_1.save(ppm_path + \"_1.ppm\")\n",
    "            new_img_2.save(ppm_path + \"_2.ppm\")\n",
    "            \n",
    "        return rgb_data_top, rgb_data_bottom\n",
    "    \n",
    "    rgb_data = PGM_to_PPM(yuv_array, TFF=False)\n",
    "    \n",
    "    # saving as ppm\n",
    "    \n",
    "    if ppm_path :\n",
    "        new_img = Image.fromarray(rgb_data)\n",
    "        new_img.save(ppm_path + \".ppm\")\n",
    "    \n",
    "    return rgb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc6064f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It worked !\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "pgm_path = './pgm_images/0.pgm'\n",
    "ppm_path = './ppm_images/0'\n",
    "generic_PGM_to_PPM(pgm_path, ppm_path)\n",
    "print(\"It worked !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd80c23b",
   "metadata": {},
   "source": [
    " <img src=\"./screenshots/ppm_real_0.png\" title=\"ppm_0\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e015d334",
   "metadata": {},
   "source": [
    "L'image PPM est identique a celle precedemment montre en PGM, tout en recuperant l'information chromatique.\n",
    "\n",
    "La fonction de conversion semble donc fonctionner comme attendu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b808e4f7",
   "metadata": {},
   "source": [
    "### Les questions 5 a 10 ont ete realise dans les fichiers project.py et pgm_to_ppm.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
